{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RjFOBmQI02AX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import STL10\n",
        "from torchvision.models import resnet18\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "7ffzUhcf07Sd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "3KbSiOX_08sj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_transform = transforms.ToTensor()\n",
        "\n",
        "augmentation_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(96),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "CUqrsOKD0-OY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled_dataset = STL10(root=\"./data\", split='unlabeled', download=True, transform=transforms.ToTensor())\n",
        "train_dataset = STL10(root=\"./data\", split='train', download=True, transform=transforms.ToTensor())\n",
        "test_dataset = STL10(root=\"./data\", split='test', download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "xdhA5au61AZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a110eb-e987-4c95-aa17-d2705416c196"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.64G/2.64G [04:28<00:00, 9.84MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "wWi3b-bG1CZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b7fd65-f6d1-4593-dd27-91164f9ea54d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_resnet_encoder():\n",
        "    model = resnet18(pretrained=False)\n",
        "    model.fc = nn.Identity()\n",
        "    return model"
      ],
      "metadata": {
        "id": "vp1KrvMG1EV4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        reps = self.encoder(x)\n",
        "        z = self.projector(reps)\n",
        "        return z"
      ],
      "metadata": {
        "id": "IwWr4HkZ12AP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simclr_loss(z1, z2, temperature=0.5):\n",
        "    z1 = nn.functional.normalize(z1, dim=1)\n",
        "    z2 = nn.functional.normalize(z2, dim=1)\n",
        "\n",
        "    batch_size = z1.size(0)\n",
        "    representations = torch.cat([z1, z2], dim=0)\n",
        "    similarity_matrix = torch.matmul(representations, representations.T)\n",
        "\n",
        "\n",
        "    mask = torch.eye(batch_size * 2, dtype=torch.bool).to(device)\n",
        "    similarity_matrix = similarity_matrix / temperature\n",
        "    similarity_matrix.masked_fill_(mask, -1e9)\n",
        "\n",
        "    positives = torch.exp(torch.sum(z1 * z2, dim=-1) / temperature)\n",
        "    negatives = torch.exp(similarity_matrix).sum(dim=-1)\n",
        "\n",
        "    loss = -torch.log(positives / (negatives[:batch_size] + negatives[batch_size:]))\n",
        "    return loss.mean()"
      ],
      "metadata": {
        "id": "zi4suoGXG1VM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_simclr(dataloader, epochs=10):\n",
        "    encoder = get_resnet_encoder().to(device)\n",
        "    model = SimCLR(encoder).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x, _ in tqdm(dataloader):\n",
        "            x1 = torch.stack([augmentation_transform(transforms.ToPILImage()(img)) for img in x])\n",
        "            x2 = torch.stack([augmentation_transform(transforms.ToPILImage()(img)) for img in x])\n",
        "            x1, x2 = x1.to(device), x2.to(device)\n",
        "\n",
        "            z1 = model(x1)\n",
        "            z2 = model(x2)\n",
        "\n",
        "            loss = simclr_loss(z1, z2)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"[SimCLR] Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    return encoder"
      ],
      "metadata": {
        "id": "RZITaN-3G1tY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BYOL(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super().__init__()\n",
        "        self.online_encoder = encoder\n",
        "        self.target_encoder = get_resnet_encoder().to(device)\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512)\n",
        "        )\n",
        "        self.target_encoder.load_state_dict(self.online_encoder.state_dict())\n",
        "        for param in self.target_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        online_proj1 = self.predictor(self.online_encoder(x1))\n",
        "        online_proj2 = self.predictor(self.online_encoder(x2))\n",
        "        with torch.no_grad():\n",
        "            target_proj1 = self.target_encoder(x1)\n",
        "            target_proj2 = self.target_encoder(x2)\n",
        "        return online_proj1, online_proj2, target_proj1.detach(), target_proj2.detach()"
      ],
      "metadata": {
        "id": "LzWcC8lt14nu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_byol(dataloader, epochs=10):\n",
        "    encoder = get_resnet_encoder().to(device)\n",
        "    model = BYOL(encoder).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x, _ in tqdm(dataloader):\n",
        "            x1 = torch.stack([augmentation_transform(transforms.ToPILImage()(img)) for img in x])\n",
        "            x2 = torch.stack([augmentation_transform(transforms.ToPILImage()(img)) for img in x])\n",
        "            x1, x2 = x1.to(device), x2.to(device)\n",
        "\n",
        "            online_proj1, online_proj2, target_proj1, target_proj2 = model(x1, x2)\n",
        "\n",
        "            loss = criterion(online_proj1, target_proj2) + criterion(online_proj2, target_proj1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"[BYOL] Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    return model.online_encoder"
      ],
      "metadata": {
        "id": "oF06y6tB16EN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BarlowTwins(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.projector(self.encoder(x))\n"
      ],
      "metadata": {
        "id": "BJRJI5sC17MR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_barlow(dataloader, epochs=10, lambd=5e-3):\n",
        "    encoder = get_resnet_encoder().to(device)\n",
        "    model = BarlowTwins(encoder).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x, _ in tqdm(dataloader):\n",
        "            x1 = torch.stack([augmentation_transform(transforms.ToPILImage()(img)) for img in x])\n",
        "            x2 = torch.stack([augmentation_transform(transforms.ToPILImage()(img)) for img in x])\n",
        "            x1, x2 = x1.to(device), x2.to(device)\n",
        "\n",
        "            z1 = model(x1)\n",
        "            z2 = model(x2)\n",
        "\n",
        "            z1_norm = (z1 - z1.mean(0)) / z1.std(0)\n",
        "            z2_norm = (z2 - z2.mean(0)) / z2.std(0)\n",
        "\n",
        "            c = torch.mm(z1_norm.T, z2_norm) / z1.size(0)\n",
        "\n",
        "            on_diag = torch.diagonal(c).add_(-1).pow_(2).sum()\n",
        "            off_diag = (c - torch.eye(c.size(0), device=c.device)).pow_(2).sum() - on_diag\n",
        "            loss = on_diag + lambd * off_diag\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"[Barlow] Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    return encoder\n"
      ],
      "metadata": {
        "id": "_PZLhxNM18k-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(encoder, dataloader):\n",
        "    encoder.eval()\n",
        "    features, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(dataloader):\n",
        "            x = x.to(device)\n",
        "            reps = encoder(x).cpu().numpy()\n",
        "            features.append(reps)\n",
        "            labels.append(y.numpy())\n",
        "    return np.vstack(features), np.concatenate(labels)"
      ],
      "metadata": {
        "id": "NLx9aK07An7v"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_probe(train_features, train_labels, test_features, test_labels):\n",
        "    clf = LogisticRegression(max_iter=5000)\n",
        "    clf.fit(train_features, train_labels)\n",
        "    preds = clf.predict(test_features)\n",
        "    acc = accuracy_score(test_labels, preds)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "q2ZA4mcrAqdo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(results):\n",
        "    names = list(results.keys())\n",
        "    scores = list(results.values())\n",
        "    plt.bar(names, scores, color='skyblue')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Сравнение качества эмбеддингов')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "iyVFtmJ8Ar-3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    simclr_encoder = train_simclr(unlabeled_loader, epochs=10)\n",
        "    byol_encoder = train_byol(unlabeled_loader, epochs=10)\n",
        "    barlow_encoder = train_barlow(unlabeled_loader, epochs=10)\n",
        "\n",
        "    print(\"\\n[SimCLR] Извлечение признаков...\")\n",
        "    simclr_features_train, simclr_labels_train = extract_features(simclr_encoder, train_loader)\n",
        "    simclr_features_test, simclr_labels_test = extract_features(simclr_encoder, test_loader)\n",
        "\n",
        "    print(\"\\n[BYOL] Извлечение признаков...\")\n",
        "    byol_features_train, byol_labels_train = extract_features(byol_encoder, train_loader)\n",
        "    byol_features_test, byol_labels_test = extract_features(byol_encoder, test_loader)\n",
        "\n",
        "    print(\"\\n[Barlow] Извлечение признаков...\")\n",
        "    barlow_features_train, barlow_labels_train = extract_features(barlow_encoder, train_loader)\n",
        "    barlow_features_test, barlow_labels_test = extract_features(barlow_encoder, test_loader)\n",
        "\n",
        "    print(\"\\nКлассификация...\")\n",
        "    acc_simclr = linear_probe(simclr_features_train, simclr_labels_train, simclr_features_test, simclr_labels_test)\n",
        "    acc_byol = linear_probe(byol_features_train, byol_labels_train, byol_features_test, byol_labels_test)\n",
        "    acc_barlow = linear_probe(barlow_features_train, barlow_labels_train, barlow_features_test, barlow_labels_test)\n",
        "\n",
        "    print(f\"SimCLR Accuracy: {acc_simclr:.4f}\")\n",
        "    print(f\"BYOL Accuracy: {acc_byol:.4f}\")\n",
        "    print(f\"Barlow Twins Accuracy: {acc_barlow:.4f}\")\n",
        "\n",
        "    plot_results({\"SimCLR\": acc_simclr, \"BYOL\": acc_byol, \"Barlow Twins\": acc_barlow})\n"
      ],
      "metadata": {
        "id": "MoxWEZCIAttW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f0aff30-6d4e-4d09-eee7-b09e2595be2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 391/391 [06:09<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SimCLR] Epoch 1, Loss: 5.4455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 365/391 [05:50<00:25,  1.03it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SimCLR показывает лучшую обобщающую способность при обучении логистической регрессии на малом объеме данных.\n",
        "\n",
        "BYOL чуть слабее, возможно, из-за того, что архитектура требует больше данных или более долгого обучения.\n",
        "\n",
        "Barlow Twins близко к BYOL, но всё ещё не обошёл SimCLR."
      ],
      "metadata": {
        "id": "0lrDXMphXPoG"
      }
    }
  ]
}